{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.path.realpath(\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "from utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "egy_joy = [\"تزغرط\", \"هيرضى\", \"تمزحو\", \"ميحرمناش\", \"متشكر\", \"هتستمتع\", \"هفرح\", \"هتضحك\", \"مريحني\"]\n",
    "egy_anger = [\"هكرهك\", \"تخرس\", \"اخرس\", \"جلنف\", \"بزيئ\", \"اندال\", \"ندل\", \"عرص\", \"وسخ\"]\n",
    "egy_disgust = [\"يمسخكم\", \"تقرف\", \"مؤرف\", \"متقرفوناش\", \"تقرفينا\", \"هيقرفه\", \"صرصار\"]\n",
    "egy_fear = [\"هخافميخافش\", \"مبنخافش\"]\n",
    "egy_sadness = [\"حزنان\", \"مبزعلش\", \"مخنوق\", \"اتبكي\", \"يبكو\", \"هعيط\", \"نكدية\", \"مصحتش\", \"مضيقاني\", \"متزعلش\", \"بتضايقنى\"]\n",
    "egy_surprise = [\"ماتوقعوش\", \"هتفاجئ\", \"هفاجئك\", \"اتفاجئنا\"]\n",
    "\n",
    "glf_joy = [\"ينحب\", \"ماقصرت\", \"سالخير\", \"مشكور\", \"لاهنتوا\", \"عقبالك\", \"يهنيكم\", \"نكتة\"]\n",
    "glf_anger = [\"مصخره\", \"كريه\", \"متخلف\", \"مبزره\", \"كرهي\", \"لطخ\", \"حقير\", \"يقهر\", \"عمى\", \"يلعن\", \"غبي\", \"لعنبو\", \"يلعنم\", \"شخصنة\"]\n",
    "glf_disgust = [\"يغث\", \"لطخ\", \"بذيء\", \"أشمط\", \"جرذ\", \"جرثوم\", \"وصخ\", \"حثاله\", \"ازق\"]\n",
    "glf_fear = [\"عجيب\", \"مفجوع\", \"مروع\", \"متخوفة\", \"مخوف\", \"خوفتني\", \"خايفين\", \"منغص\"]\n",
    "glf_sadness = [\"ضايقني\", \"شكى\", \"يبكيني\", \"ضايق\", \"قهر\", \"تبكيك\", \"يخذلك\", \"خنق\", \"خذلان\", \"قسى\", \"يحزني\", \"أحزن\", \"أبكى\", \"غثيث\", \"حز\", \"فاقدن\", \"أفتك\"]\n",
    "glf_surprise = [\"هول\", \"مهول\", \"ترويع\", \"أعجب\", \"مفاجئه\", \"هبل\", \"فجأه\"]\n",
    "\n",
    "egy_lexicon_dict = {\"JOY\" : egy_joy, \"ANGER\" : egy_anger, \"DISGUST\" : egy_disgust, \"FEAR\" : egy_fear, \"SADNESS\" : egy_sadness, \"SURPRISE\" : egy_surprise}\n",
    "glf_lexicon_dict = {\"JOY\" : glf_joy, \"ANGER\" : glf_anger, \"DISGUST\" : glf_disgust, \"FEAR\" : glf_fear, \"SADNESS\" : glf_sadness, \"SURPRISE\" : glf_surprise}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lexicons(text, lexicon_list):\n",
    "    text_lexicon = []\n",
    "    for lexicon in lexicon_list:\n",
    "        if lexicon in text:\n",
    "            text_lexicon.append(lexicon)\n",
    "    return \" \".join(text_lexicon)\n",
    "\n",
    "def contains_lexicon(text, lexicons):\n",
    "    for lexicon in lexicons:\n",
    "        if lexicon in text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_emotion(text, lexicon_dict):\n",
    "    emotion_counter = {\"JOY\" : 0, \"ANGER\" : 0, \"DISGUST\" : 0, \"FEAR\" : 0, \"SADNESS\" : 0, \"SURPRISE\" : 0}\n",
    "    \n",
    "    for emotion in list(emotion_counter.keys()):\n",
    "        for lexicon in lexicon_dict[emotion]:\n",
    "            if lexicon in text:\n",
    "                emotion_counter[emotion] += 1\n",
    "\n",
    "    emotion_counter_sorted = {k: v for k, v in sorted(emotion_counter.items(), key=lambda item: item[1], reverse=True)}\n",
    "    emotion_counter_sorted_values = list(emotion_counter_sorted.values())\n",
    "    if emotion_counter_sorted_values[0] == emotion_counter_sorted_values[1]:\n",
    "        return \"UNKNOWN\"\n",
    "    return list(emotion_counter_sorted.keys())[0]\n",
    "\n",
    "def display_lexicons(df, glf=False):\n",
    "    if glf:\n",
    "        for text in df[df[\"Contains_Lexicon\"]].sample(20)[\"Text\"]:\n",
    "            formattedText = []\n",
    "            for word in text.split():\n",
    "                if any(lexicon in word for lexicon in glf_joy):\n",
    "                    formattedText.append(colored(word,'white','on_green'))\n",
    "                elif any(lexicon in word for lexicon in glf_anger):\n",
    "                    formattedText.append(colored(word,'white','on_red'))\n",
    "                else: \n",
    "                    formattedText.append(word)\n",
    "            print(\" \".join(formattedText))\n",
    "            print(\"-----------------\")\n",
    "    else:\n",
    "        for text in df[df[\"Contains_Lexicon\"]].sample(20)[\"Text\"]:\n",
    "            formattedText = []\n",
    "            for word in text.split():\n",
    "                if any(lexicon in word for lexicon in egy_joy):\n",
    "                    formattedText.append(colored(word,'white','on_green'))\n",
    "                elif any(lexicon in word for lexicon in egy_anger):\n",
    "                    formattedText.append(colored(word,'white','on_red'))\n",
    "                else: \n",
    "                    formattedText.append(word)\n",
    "            print(\" \".join(formattedText))\n",
    "            print(\"-----------------\")\n",
    "\n",
    "def process(df, lexicon_dict):\n",
    "    df[\"Contains_Lexicon\"] = df[\"Text\"].apply(contains_lexicon, args=([val for lst in lexicon_dict.values() for val in lst],))\n",
    "    df[\"Lexicon\"] = df[\"Text\"].apply(get_lexicons, args=([val for lst in lexicon_dict.values() for val in lst],))\n",
    "    df[\"Emotion\"] = df[\"Text\"].apply(get_emotion, args=(lexicon_dict,))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMADC Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1408456 entries, 0 to 256631\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   Text    1408456 non-null  object\n",
      " 1   Region  1408456 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 32.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df = get_SMADC_folder_data(\".\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_egy = df[df[\"Region\"] == \"EGY\"]\n",
    "df_glf = df[df[\"Region\"] == \"GLF\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EGY Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdul\\AppData\\Local\\Temp\\ipykernel_21004\\1857228990.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Contains_Lexicon\"] = df[\"Text\"].apply(contains_lexicon, args=([val for lst in lexicon_dict.values() for val in lst],))\n",
      "C:\\Users\\Abdul\\AppData\\Local\\Temp\\ipykernel_21004\\1857228990.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Lexicon\"] = df[\"Text\"].apply(get_lexicons, args=([val for lst in lexicon_dict.values() for val in lst],))\n",
      "C:\\Users\\Abdul\\AppData\\Local\\Temp\\ipykernel_21004\\1857228990.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Emotion\"] = df[\"Text\"].apply(get_emotion, args=(lexicon_dict,))\n"
     ]
    }
   ],
   "source": [
    "df_egy = process(df_egy, egy_lexicon_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_egy_unknown = df_egy[df_egy[\"Emotion\"] == \"UNKNOWN\"]\n",
    "df_egy = df_egy[df_egy[\"Emotion\"] != \"UNKNOWN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ANGER</th>\n",
       "      <td>17410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DISGUST</th>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SADNESS</th>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JOY</th>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SURPRISE</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FEAR</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Text\n",
       "Emotion        \n",
       "ANGER     17410\n",
       "DISGUST     591\n",
       "SADNESS     536\n",
       "JOY         308\n",
       "SURPRISE     36\n",
       "FEAR         10"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_egy.groupby([\"Emotion\"]).agg({\"Text\" : \"count\"}).sort_values(\"Text\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UNKNOWN</th>\n",
       "      <td>603176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Text\n",
       "Emotion        \n",
       "UNKNOWN  603176"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_egy_unknown.groupby([\"Emotion\"]).agg({\"Text\" : \"count\"}).sort_values(\"Text\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lexicon</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>وسخ</th>\n",
       "      <td>9608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>عرص</th>\n",
       "      <td>6630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>عرص وسخ</th>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>تقرف</th>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>اخرس</th>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>متزعلش</th>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ندل</th>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>مخنوق</th>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>متشكر</th>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>يبكو</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>هتستمتع</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>هعيط</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>تخرس</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>مؤرف</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>هتضحك</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>اندال</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>هفرح</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>بزيئ</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>صرصار</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>هفاجئك</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>هيرضى</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>جلنف</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>نكدية</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>اخرس وسخ</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>مبنخافش</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>مبزعلش</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>تمزحو</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>تقرف متقرفوناش</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>هتفاجئ</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ميحرمناش</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>هيقرفه</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>يمسخكم</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>تقرف تقرفينا</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>مريحني</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ماتوقعوش</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>حزنان</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>تزغرط</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>بتضايقنى</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>هكرهك</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>تخرس وسخ</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>مضيقاني</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>مصحتش</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>اتفاجئنا</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>اتبكي</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>اندال وسخ</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>اخرس عرص</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ندل وسخ</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ندل عرص</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>اخرس عرص وسخ</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Text\n",
       "Lexicon             \n",
       "وسخ             9608\n",
       "عرص             6630\n",
       "عرص وسخ          620\n",
       "تقرف             507\n",
       "اخرس             240\n",
       "متزعلش           174\n",
       "ندل              170\n",
       "مخنوق            162\n",
       "متشكر            138\n",
       "يبكو              88\n",
       "هتستمتع           74\n",
       "هعيط              58\n",
       "تخرس              50\n",
       "مؤرف              34\n",
       "هتضحك             34\n",
       "اندال             26\n",
       "هفرح              18\n",
       "بزيئ              16\n",
       "صرصار             16\n",
       "هفاجئك            14\n",
       "هيرضى             12\n",
       "جلنف              12\n",
       "نكدية             12\n",
       "اخرس وسخ          12\n",
       "مبنخافش           10\n",
       "مبزعلش            10\n",
       "تمزحو             10\n",
       "تقرف متقرفوناش    10\n",
       "هتفاجئ             8\n",
       "ميحرمناش           8\n",
       "هيقرفه             8\n",
       "يمسخكم             8\n",
       "تقرف تقرفينا       8\n",
       "مريحني             8\n",
       "ماتوقعوش           8\n",
       "حزنان              8\n",
       "تزغرط              6\n",
       "بتضايقنى           6\n",
       "هكرهك              6\n",
       "تخرس وسخ           6\n",
       "مضيقاني            6\n",
       "مصحتش              6\n",
       "اتفاجئنا           6\n",
       "اتبكي              6\n",
       "اندال وسخ          4\n",
       "اخرس عرص           4\n",
       "ندل وسخ            2\n",
       "ندل عرص            2\n",
       "اخرس عرص وسخ       2"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_egy.groupby([\"Lexicon\"]).agg({\"Text\" : \"count\"}).sort_values(\"Text\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_lexicons(df_egy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_egy.to_csv(\"EGY_EMOTIONS.csv\")\n",
    "df_egy_unknown.to_csv(\"EGY_UNKOWN.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLF Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdul\\AppData\\Local\\Temp\\ipykernel_21004\\1857228990.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Contains_Lexicon\"] = df[\"Text\"].apply(contains_lexicon, args=([val for lst in lexicon_dict.values() for val in lst],))\n",
      "C:\\Users\\Abdul\\AppData\\Local\\Temp\\ipykernel_21004\\1857228990.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Lexicon\"] = df[\"Text\"].apply(get_lexicons, args=([val for lst in lexicon_dict.values() for val in lst],))\n",
      "C:\\Users\\Abdul\\AppData\\Local\\Temp\\ipykernel_21004\\1857228990.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"Emotion\"] = df[\"Text\"].apply(get_emotion, args=(lexicon_dict,))\n"
     ]
    }
   ],
   "source": [
    "df_glf = process(df_glf, glf_lexicon_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glf_unknown = df_glf[df_glf[\"Emotion\"] == \"UNKNOWN\"]\n",
    "df_glf = df_glf[df_glf[\"Emotion\"] != \"UNKNOWN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>UNKNOWN</th>\n",
       "      <td>175001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Text\n",
       "Emotion        \n",
       "UNKNOWN  175001"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_glf_unknown.groupby([\"Emotion\"]).agg({\"Text\" : \"count\"}).sort_values(\"Text\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emotion</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SADNESS</th>\n",
       "      <td>1701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JOY</th>\n",
       "      <td>1318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANGER</th>\n",
       "      <td>924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SURPRISE</th>\n",
       "      <td>830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FEAR</th>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DISGUST</th>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Text\n",
       "Emotion       \n",
       "SADNESS   1701\n",
       "JOY       1318\n",
       "ANGER      924\n",
       "SURPRISE   830\n",
       "FEAR       286\n",
       "DISGUST    158"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_glf.groupby([\"Emotion\"]).agg({\"Text\" : \"count\"}).sort_values(\"Text\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lexicon</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>حز</th>\n",
       "      <td>1085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>مشكور</th>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>هول</th>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ماقصرت</th>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>غبي</th>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>شكى حز</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>خذلان قسى</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>خذلان حز</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>حقير غبي</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>قهر خنق</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Text\n",
       "Lexicon        \n",
       "حز         1085\n",
       "مشكور       866\n",
       "هول         509\n",
       "ماقصرت      318\n",
       "غبي         278\n",
       "...         ...\n",
       "شكى حز        1\n",
       "خذلان قسى     1\n",
       "خذلان حز      1\n",
       "حقير غبي      1\n",
       "قهر خنق       1\n",
       "\n",
       "[91 rows x 1 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_glf.groupby([\"Lexicon\"]).agg({\"Text\" : \"count\"}).sort_values(\"Text\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_lexicons(df_glf, glf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glf.to_csv(\"GLF_EMOTIONS.csv\")\n",
    "df_glf_unknown.to_csv(\"GLF_UNKOWN.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_annotated_data_folder_data(\"..\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_egy = df[df[\"Region\"] == \"EGY\"]\n",
    "df_glf = df[df[\"Region\"] == \"GLF\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EGY Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_egy = process(df_egy, egy_joy, egy_anger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_egy.groupby([\"Emotion\"]).agg({\"Text\" : \"count\"}).sort_values(\"Text\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_egy.groupby([\"Lexicon\"]).agg({\"Text\" : \"count\"}).sort_values(\"Text\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_lexicons(df_egy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLF Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glf = process(df_glf, glf_joy, glf_anger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glf.groupby([\"Emotion\"]).agg({\"Text\" : \"count\"}).sort_values(\"Text\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glf.groupby([\"Lexicon\"]).agg({\"Text\" : \"count\"}).sort_values(\"Text\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_lexicons(df_glf, glf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DART Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_dart_folder_data(\"..\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_egy = df[df[\"Region\"] == \"EGY\"]\n",
    "df_glf = df[df[\"Region\"] == \"GLF\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EGY Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_egy = process(df_egy, egy_joy, egy_anger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_egy.groupby([\"Emotion\"]).agg({\"Text\" : \"count\"}).sort_values(\"Text\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_egy.groupby([\"Lexicon\"]).agg({\"Text\" : \"count\"}).sort_values(\"Text\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_lexicons(df_egy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLF Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glf = process(df_glf, glf_joy, glf_anger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glf.groupby([\"Emotion\"]).agg({\"Text\" : \"count\"}).sort_values(\"Text\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_glf.groupby([\"Lexicon\"]).agg({\"Text\" : \"count\"}).sort_values(\"Text\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_lexicons(df_glf, glf=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "94acc959f51252fc8d180630cbd20cb6797ac8c41bdcd6d68d728cbf9ec90b92"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
